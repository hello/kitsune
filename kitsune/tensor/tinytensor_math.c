#include "tinytensor_math.h"
#include <assert.h>

const static int8_t tanh_table[356] = {0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,28,29,30,31,32,33,34,35,36,37,38,39,40,41,41,42,43,44,45,46,47,48,48,49,50,51,52,53,53,54,55,56,57,57,58,59,60,61,61,62,63,64,64,65,66,67,67,68,69,69,70,71,72,72,73,74,74,75,76,76,77,77,78,79,79,80,81,81,82,82,83,83,84,85,85,86,86,87,87,88,88,89,89,90,90,91,91,92,92,93,93,94,94,95,95,95,96,96,97,97,98,98,98,99,99,100,100,100,101,101,101,102,102,103,103,103,104,104,104,105,105,105,106,106,106,106,107,107,107,108,108,108,108,109,109,109,110,110,110,110,111,111,111,111,112,112,112,112,112,113,113,113,113,114,114,114,114,114,115,115,115,115,115,115,116,116,116,116,116,116,117,117,117,117,117,117,118,118,118,118,118,118,118,119,119,119,119,119,119,119,119,120,120,120,120,120,120,120,120,120,121,121,121,121,121,121,121,121,121,121,122,122,122,122,122,122,122,122,122,122,122,122,123,123,123,123,123,123,123,123,123,123,123,123,123,123,124,124,124,124,124,124,124,124,124,124,124,124,124,124,124,124,124,124,124,125,125,125,125,125,125,125,125,125,125,125,125,125,125,125,125,125,125,125,125,125,125,125,125,125,125,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,127};

const static int16_t exp_table[1025] = {2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,10,10,10,10,10,10,10,10,10,10,10,10,11,11,11,11,11,11,11,11,11,11,11,11,12,12,12,12,12,12,12,12,12,12,12,13,13,13,13,13,13,13,13,13,13,14,14,14,14,14,14,14,14,14,15,15,15,15,15,15,15,15,16,16,16,16,16,16,16,16,17,17,17,17,17,17,17,17,18,18,18,18,18,18,18,19,19,19,19,19,19,19,20,20,20,20,20,20,21,21,21,21,21,21,22,22,22,22,22,22,23,23,23,23,23,23,24,24,24,24,24,25,25,25,25,25,26,26,26,26,26,27,27,27,27,27,28,28,28,28,29,29,29,29,29,30,30,30,30,31,31,31,31,32,32,32,32,33,33,33,33,34,34,34,34,35,35,35,36,36,36,36,37,37,37,38,38,38,38,39,39,39,40,40,40,41,41,41,42,42,42,43,43,43,44,44,44,45,45,45,46,46,46,47,47,47,48,48,49,49,49,50,50,51,51,51,52,52,53,53,53,54,54,55,55,55,56,56,57,57,58,58,59,59,60,60,60,61,61,62,62,63,63,64,64,65,65,66,66,67,67,68,69,69,70,70,71,71,72,72,73,74,74,75,75,76,76,77,78,78,79,79,80,81,81,82,83,83,84,85,85,86,87,87,88,89,89,90,91,91,92,93,94,94,95,96,97,97,98,99,100,100,101,102,103,104,104,105,106,107,108,109,109,110,111,112,113,114,115,116,117,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,141,142,143,144,145,146,147,148,150,151,152,153,154,156,157,158,159,161,162,163,164,166,167,168,170,171,172,174,175,176,178,179,181,182,183,185,186,188,189,191,192,194,195,197,198,200,201,203,205,206,208,209,211,213,214,216,218,219,221,223,225,226,228,230,232,234,235,237,239,241,243,245,247,249,251,253,255,257,259,261,263,265,267,269,271,273,275,277,280,282,284,286,288,291,293,295,298,300,302,305,307,309,312,314,317,319,322,324,327,329,332,335,337,340,343,345,348,351,353,356,359,362,365,367,370,373,376,379,382,385,388,391,394,397,400,404,407,410,413,416,420,423,426,430,433,436,440,443,447,450,454,457,461,465,468,472,476,479,483,487,491,495,498,502,506,510,514,518,522,526,531,535,539,543,547,552,556,560,565,569,574,578,583,587,592,597,601,606,611,615,620,625,630,635,640,645,650,655,660,665,671,676,681,687,692,697,703,708,714,720,725,731,737,742,748,754,760,766,772,778,784,790,796,803,809,815,822,828,835,841,848,854,861,868,875,882,888,895,902,910,917,924,931,938,946,953,961,968,976,983,991,999,1007,1015,1023,1031,1039,1047,1055,1063,1072,1080,1089,1097,1106,1114,1123,1132,1141,1150,1159,1168,1177,1186,1196,1205,1214,1224,1234,1243,1253,1263,1273,1283,1293,1303,1313,1323,1334,1344,1355,1365,1376,1387,1398,1409,1420,1431,1442,1453,1465,1476,1488,1500,1511,1523,1535,1547,1559,1572,1584,1596,1609,1621,1634,1647,1660,1673,1686,1699,1713,1726,1740,1753,1767,1781,1795,1809,1823,1837,1852,1866,1881,1896,1911,1926,1941,1956,1971,1987,2002,2018,2034,2050,2066,2082,2098,2115,2131,2148,2165,2182,2199,2216,2234,2251,2269,2287,2305,2323,2341,2359,2378,2396,2415,2434,2453,2472,2492,2511,2531,2551,2571,2591,2611,2632,2653,2673,2694,2715,2737,2758,2780,2802,2824,2846,2868,2891,2913,2936,2959,2982,3006,3029,3053,3077,3101,3125,3150,3175,3200,3225,3250,3275,3301,3327,3353,3379,3406,3433,3460,3487,3514,3542,3569,3597,3626,3654,3683,3712,3741,3770,3800,3829,3859,3890,3920,3951,3982,4013,4045,4076,4108,4141,4173,4206,4239,4272,4306,4339,4373,4408,4442,4477,4512,4548,4583,4619,4655,4692,4729,4766,4803,4841,4879,4917,4956,4995,5034,5073,5113,5153,5193,5234,5275,5317,5358,5400,5443,5485,5528,5572,5615,5660,5704,5749,5794,5839,5885,5931,5978,6025,6072,6119,6167,6216,6265,6314,6363,6413,6463,6514,6565,6617,6669,6721,6774,6827,6880,6934,6989};

int32_t tinymath_abs_int8(int8_t x) {
    if (((uint8_t)x) == 0x80) {
        x++;
    }
    
    return x >= 0 ? x : -x;
}

int32_t tinymath_abs_int32(int32_t x) {
    if (((uint32_t)x) == 0x80000000) {
        x++;
    }

    return x >= 0 ? x : -x;
}

void tinytensor_descale(Weight_t * y, int8_t * out_scale, int32_t x, int8_t in_scale) {
    //make it fit in 8 bits
    uint8_t i;
    int32_t ux = tinymath_abs_int32(x);
    
    for (i = 0; i < 24; i++) {
        if (  (ux >> i) <= 127 ) {
            break;
        }
    }
    
    *out_scale = in_scale - i;
    *y = x >> i;
    
}

void tinytensor_tanh(Weight_t * y, int8_t * out_scale, int32_t x,int8_t in_scale) {
    const static uint32_t k_max_len = sizeof(tanh_table) / sizeof(tanh_table[0]);
    const uint8_t sign = x < 0;
    Weight_t yy = 0x7F;
    
    *out_scale = 0;
    
    x = tinymath_abs_int32(x);
    
    if (in_scale > 0) {
        x >>= in_scale;
    }
    
    if (in_scale < 0) {
        x <<= -in_scale;
    }
    
    if (x < k_max_len) {
        yy = tanh_table[x];
    }


    if (sign) {
        *y = -yy;
        return;
    }

    *y = yy;
}

//(tanh + 1) / 2 == sigmoid
//crud, but should work okay
void tinytensor_sigmoid(Weight_t * y, int8_t * out_scale, int32_t x,int8_t in_scale) {
    Weight_t tanh;
    int16_t temp16;
    
    tinytensor_tanh(&tanh,out_scale,x,in_scale);
    temp16 = tanh;
    
    //add one
    temp16 += (1 << QFIXEDPOINT);
    
    //divide by two
    temp16 >>= 1;
    
    if (temp16 > MAX_WEIGHT) {
        temp16 = MAX_WEIGHT;
    }
    
    *y = (Weight_t)temp16;
    *out_scale = 0;
}


void tinytensor_vec_softmax_in_place(Weight_t * xvec, uint32_t len, int8_t in_scale) {
    uint32_t i;
    int32_t temp32;
    int32_t val;
    temp32 = 0;
    for (i = 0; i < len; i++) {
        val = xvec[i];
        
        if (in_scale > 0) {
            val >>= in_scale;
        }
        
        if (in_scale < 0) {
            val <<= -in_scale;
        }
        
        if (val > 512) {
            val = 512;
        }
        
        if (val < -512) {
            val = -512;
        }
        
        val += 512;
        
        assert(val >= 0 && val <= 1024);
        
        temp32 += exp_table[val];
    }
    
    for (i = 0; i < len; i++) {
        val = xvec[i];
        
        if (in_scale > 0) {
            val >>= in_scale;
        }
        
        if (in_scale < 0) {
            val <<= -in_scale;
        }
        
        if (val > 512) {
            val = 512;
        }
        
        if (val < -512) {
            val = -512;
        }

        val += 512;
        
        assert(val >= 0 && val <= 1024);

        val = (exp_table[val] << QFIXEDPOINT) / temp32;
        
        if (val > MAX_WEIGHT) {
            val = MAX_WEIGHT;
        }
        
        if (val < -MAX_WEIGHT) {
            val = -MAX_WEIGHT;
        }
        
        xvec[i] = val;
        
    }
    
}


void tinytensor_linear(Weight_t * y, int8_t * out_scale, int32_t x,int8_t in_scale) {
    
    if (x > MAX_WEIGHT) {
        x = MAX_WEIGHT;
    }
    
    if (x < -MAX_WEIGHT) {
        x = -MAX_WEIGHT;
    }
    
    *y = x;
    *out_scale = in_scale;
}


void tinytensor_relu(Weight_t * y, int8_t * out_scale, int32_t x,int8_t in_scale) {
    x =  x < 0 ? 0 : x;
    
    if (x > MAX_WEIGHT) {
        x = MAX_WEIGHT;
    }
    
    *y = x;
    *out_scale = in_scale;

}




int8_t tiny_tensor_get_scaling(int32_t x) {
    int8_t i;
    
    if (x == 0) {
        return 0;
    }

    //find max scaling
    x = tinymath_abs_int32(x);
    
    for (i = 0; i < 8; i++) {
        if (( ((int16_t)x) << i) > MAX_WEIGHT/2) {
            break;
        }
    }
    
    return i;
    
}

inline int8_t tiny_tensor_get_descaling(int32_t x) {
    int8_t i;

    x = tinymath_abs_int32(x);
    
    for (i = 0; i < 31; i++) {
        if ((x >> i) <= MAX_WEIGHT) {
            break;
        }
    }
    
    return i;
    
}

int8_t tiny_tensor_compare_scaled_numbers(const Weight_t x1, const int8_t scale1, const Weight_t x2, const int8_t scale2) {
    int32_t xx1 = x1 << 16;
    int32_t xx2 = x2 << 16;
    
    xx1 = tinymath_abs_int32(xx1);
    xx2 = tinymath_abs_int32(xx2);
    
    if (scale1 > 0) {
        xx1 >>= scale1;
    }
    else {
        xx1 <<= -scale1;
    }
    
    if (scale2 > 0) {
        xx2 >>= scale2;
    }
    else {
        xx2 <<= -scale2;
    }
  
    
    if (xx1 > xx2) {
        return 1;
    }
    
    if (xx2 > xx1) {
        return -1;
    }
    
    return 0;
    
}



